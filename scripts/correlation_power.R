
  library(dplyr)
  library(ggplot2)
  library(viridis)


# Planning a sample size for test-retest

# We are focusing on correlations (r), so we need to use Fisher's transoform
# (r -> z) since the sampling distribution of r is often skewed and while for z
# it's Gaussian.

  r_trans <- function(r){return(0.5 * log((1 + r)/(1 - r)))} # Fisher's xform
  rev_trans <- function(z){return((exp(2*z) - 1)/ (exp(2*z) + 1))} # xform back

# "Simple" approach ------------------------------------------------------------

# Here we treat the problem like on of non-inferiority. That is, we set up
# a null sampling distribution of r = 0.8. We then set up a one-sided test
# of H0: r >= 0.8 vs. H1: r < 0.8.

# At different sample sizes, compute the 1 sided (5%) value of the null
# sampling distribution.

  tar <- 0.75
  tar <- 0.80

  results <- list(); k <- 1
  for(n in 10:200){
    se  <- 1 / sqrt(n - 3) # get se for transformed r and n
    z <- r_trans(tar)
    crit <- qnorm(0.05, z, se)
    results[[k]] <- data.frame(
      n = n,
      crit_z = crit,
      crit_r = rev_trans(crit)
    )
    k <- k + 1
  }

  results_1 <- do.call(rbind, results)

  ggplot(results_1, aes(x = n, y = crit_r)) +
    geom_line(size = 1, color = viridis(1)) +
    ylab("Critical Rejection Value (r)") +
    xlab("n participants") +
    theme_minimal()


# Given n = X, what is power at different alternative sampling distrubutions?

  results <- list(); k <- 1;
  for(n in c(50, 100, 150, 200)){
    for(effect in seq(0.01, tar - 0.01, by = 0.01)){
      se  <- 1 / sqrt(n - 3) # get se for transformed r and n
      z <- r_trans(tar)
      crit <- qnorm(0.05, z, se)
      power <- pnorm(crit, r_trans(effect), se, lower.tail = TRUE)
      results[[k]] <- data.frame(
        effect = effect,
        n = n,
        Power = power
      )
      k <- k + 1
    }
  }

  results_2 <- do.call(rbind, results)
  ggplot(results_2, aes(x = effect, y = Power, color = factor(n), group = n)) +
    geom_line(size = 1) +
    scale_color_viridis("n participants", discrete = TRUE) +
    xlim(c(0.5, 0.8)) +
    xlab("Alternative effect (r)") +
    theme_minimal()


# Given n = x, what are the alternatives that give 80% power

  results <- list(); k <- 1;
  for(n in 10:300){
    for(effect in seq(0.5, tar - 0.1, by = 0.01)){
      for(pwr in c(0.80, 0.85, 0.90)){
      se  <- 1 / sqrt(n - 3) # get se for transformed r and n
      z <- r_trans(tar)
      crit <- qnorm(0.05, z, se)
      power <- round(pnorm(crit, r_trans(effect), se, lower.tail = TRUE), 2)
      results[[k]] <- data.frame(
        effect = effect,
        n = n,
        Power = pwr
      ) %>%
        filter(power == pwr)
      k <- k + 1
      }
    }
  }


  results_3 <- do.call(rbind, results)
  ggplot(results_3, aes(x = n, y = effect, color = factor(Power), group = Power)) +
    geom_smooth(size = 1, se = FALSE) +
    scale_color_viridis("Power", discrete = TRUE) +
    xlab("n Participants") +
    theme_minimal()

  filter(results_3, Power == 0.80) %>% View()

  library(pwr)


# This says that is we recruited

# If I see a value < 0.8, and 0.8 is true, what is prob is mistaken rejection?
# reject when prob of at least 0.8 > 95%

# As function of sample size:
# What do the data look like when generated by H1 r <  0.8
# What do the data look like when generated by H2 r >= 0.8

# Can I increase sample size enough that I can get enough separation between
# these two distributions?

  under <- seq(r_trans(0.01), r_trans(0.8), by = 0.01) # H1 possible values
  over <- seq(r_trans(0.81), r_trans(0.99), by = 0.01) # H2 possible values

  post_dist <- function(n, vals){
    se  <- 1 / sqrt(n - 3) # get se for transformed r and n
    results <- list(); k <- 1
    for(i in vals){ # For every possible central parameter under HX
      results[[k]] <- data_frame(
        parameter = i,
        obs = seq(r_trans(0.01), r_trans(0.99), by = 0.01), # ~ data
        density = dnorm(obs, i, se), # Given i and se, what is prob of observed value
        total = sum(density),
        prob = density /  total
        )
      k <- k + 1
    }

    results <- do.call(rbind, results)
    results2 <- mutate(results, total = sum(density)) %>%
      group_by(obs) %>% # Take each possible value
      summarise(sum = sum(density), # Sum all the densities from under the all the parameters
                prob = sum / mean(total))

    return(list(results, results2))
  }

  x <- post_dist(10, under)

  ggplot(x[[2]], aes(x = rev_trans(obs), y = prob)) +
    geom_line()

  DescTools::AUC(x[[2]]$obs, x[[2]]$prob)


# ggplot(results, aes(x = parameter, y = density, group = obs)) +
#   geom_line() +
#   facet_wrap(~obs)

  ggplot(dist(100, under), aes(x = rev_trans(obs), y = prob)) +
    geom_line()

  ggplot(dist(100, over), aes(x = rev_trans(obs), y = prob)) +
    geom_line()

  bind_rows(
    dist(1000, under) %>% mutate(group = "< 0.8"),
    dist(1000, over) %>% mutate(group = ">= 0.8"),
  ) %>%
    ggplot(aes(x = rev_trans(obs), y = prob, color = factor(group))) +
    geom_line(size = 2) +
    xlab("Correlation") +
    ylab("Posterior Probability") +
    theme_minimal() +
    scale_color_viridis("", discrete = TRUE, end = 0.5)


  for(n in 10:200){
    se  <- 1 / sqrt(n - 3) # get se for transformed r and n
    pnorm(R_t, R_t, se)
  }




# OLD --------------------------------------------------------------------------

  R <- 0.8
  R_t <- r_trans(R)
  N <- 1000
  sigma = matrix(c(1, R, R, 1), nrow = 2)
  results <- list(); k <- 1
  for(n in 10:200){# Data in Pairs
    for(effect in c(0.5, 0.6, 0.7, 0.75, 0.78)){ # Rejection values
      se  <- 1 / sqrt(n - 3) # get se for transformed r and n
      crit <- r_trans(effect) + 1.644 * se
      power <- pnorm(crit, R_t, se, FALSE)
      # r   <- replicate(N, cor(MASS::mvrnorm(n, c(0,0), sigma))[2,1]) # sim data
      # r_t <- r_trans(r) # Fisher's xform
      # out <- r_t < crit
      # dat <- data.frame(
      #   n = n, se = se, effect = effect,
      #   power = table(out)["FALSE"] / sum(table(out))
      #   )
      dat <- data.frame(
        n = n, se = se, effect = effect,
        power = power
      )
      results[[k]] <- dat
      k <- k + 1
    }
  }

  results <- do.call(rbind, results)

  ggplot(results, aes(x = n, y = power, color = factor(effect))) +
    geom_smooth(se = FALSE) +
    scale_color_viridis("Null effect", discrete = TRUE) +
    theme_minimal()# One sided test for H0: r >= 0.8 vs H1: r < 0.8

  # If you reverse this, it's of course the same.
  results2 <- list(); k <- 1
  for(n in 10:200){# Data in Pairs
    for(effect in c(0.5, 0.6, 0.7, 0.75, 0.78)){ # Rejection values
      se  <- 1 / sqrt(n - 3) # get se for transformed r and n
      crit <- R_t - (1.644 * se)
      power <- pnorm(crit, r_trans(effect), se)
      # r   <- replicate(N, cor(MASS::mvrnorm(n, c(0,0), sigma))[2,1]) # sim data
      # r_t <- r_trans(r) # Fisher's xform
      # out <- r_t < crit
      # dat <- data.frame(
      #   n = n, se = se, effect = effect,
      #   power = table(out)["FALSE"] / sum(table(out))
      #   )
      dat <- data.frame(
        n = n, se = se, effect = effect,
        power = power
      )
      results2[[k]] <- dat
      k <- k + 1
    }
  }

  results2 <- do.call(rbind, results2)

  ggplot(results2, aes(x = n, y = power, color = factor(effect))) +
    geom_smooth(se = FALSE) +
    scale_color_viridis("Alt effect", discrete = TRUE) +
    theme_minimal()

